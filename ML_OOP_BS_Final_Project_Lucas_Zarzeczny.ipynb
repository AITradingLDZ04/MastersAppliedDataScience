{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Object Oriented Programming, Machine Learning, and Beautiful Soup to Predict Sentiment of Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Overview:\n",
    "- Data Source: The data that I use is from the Stanford Sentiment Treebank (SST-5, or SST-fine-grained) dataset\n",
    "    - This data is used to train the model\n",
    "    - It was designed to help evaluate a model’s ability to understand representations of sentence structure\n",
    "    - SST-5 consists of 11,855 sentences extracted from movie reviews with fine-grained sentiment labels [1–5], as well as 215,154 phrases that compose each sentence in the dataset.\n",
    "    - https://nlp.stanford.edu/sentiment/\n",
    "    - This site provides raw data files for testing, training, and validation\n",
    "- Data Preparation\n",
    "    - I load the raw data files into my working directory\n",
    "    - I use a function that modifies these raw data files and returns three new files in the format that is needed to create a dataframe\n",
    "    - I use matplotlib to return a quick visualization of the distribution of the training data\n",
    "- Machine Learning\n",
    "    - Object Oriented Programming\n",
    "        - I create five classes that make it easier to read in data and perform machine learning on that data\n",
    "        - For instance, if we receive the training data every week with new data, I can just initiate the class and everything would be completed within a few seconds.\n",
    "        - I create a base class  (standard procedures for uploading and modifying the datasets), a Vadar Sentiment Class (to perform Vadar Sentiment Machine Learning), a Logistic Regression Class (to perform logistic regression  Machine Learning), and a SVM Class (to perform support vector machine Machine Learning).\n",
    "        - I initiate the classes for each machine learning model, create a column for the prediction scores, and output the accuracy scores by calling the class Base with the accuracy function.\n",
    "- Unstructured Data - IMDb Movie Review\n",
    "    - Finally, I want to implement one of the machine learning models to predict a sentiment score for data not seen before.\n",
    "    - I use BeautifulSoup to scrape the IMDb website \n",
    "        - Specifically, I focus on the webpage that provides user reviews for The Shawshank Redemption.\n",
    "        - https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3\n",
    "    - I create a function and class to extract one of the reviews \n",
    "    - Finally, I initiate the Vadar Sentiment Class to predict a sentiment score for that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pytreebank\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lucasdanielzarzeczny'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory\n",
    "# Change the working directory\n",
    "os.chdir('C:\\\\Users\\\\lucasdanielzarzeczny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucasdanielzarzeczny\n"
     ]
    }
   ],
   "source": [
    "# check current directory is in place\n",
    "currentDirectory = os.getcwd()\n",
    "print(currentDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a path for the file output (notebook)\n",
    "out_path = os.path.join(sys.path[0], 'sst_{}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data sets from the pytreebank library (into current working director)\n",
    "dataset = pytreebank.load_sst('./raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store train, dev and test in separate files \n",
    "# This function takes the raw data files (train, test, and dev) and outputs three different files\n",
    "# These new files create a label (rating) for each line that is separated by a tab\n",
    "\n",
    "for category in ['train', 'test', 'dev']:\n",
    "    with open(out_path.format(category), 'w') as outfile:\n",
    "        for item in dataset[category]:\n",
    "            outfile.write(\"__label__{}\\t{}\\n\".format(\n",
    "                item.to_labeled_lines()[0][0] + 1,\n",
    "                item.to_labeled_lines()[0][1]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n"
     ]
    }
   ],
   "source": [
    "# Print the length of the training set\n",
    "print(len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas to create a dataframe\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lucasdanielzarzeczny'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucasdanielzarzeczny\n"
     ]
    }
   ],
   "source": [
    "# Read train data\n",
    "# check current directory is in place\n",
    "currentDirectory = os.getcwd()\n",
    "print(currentDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data and split the columns by a comma and create two new headings\n",
    "df = pd.read_csv(\"sst_train.csv\", sep=',', header=None, names=['truth', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the label with a blank so the number just exists (the level)\n",
    "df['truth'] = df['truth'].str.replace('__label__', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the number portion to a category since we are ranking the movies\n",
    "df['truth'] = df['truth'].astype(int).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  truth                                               text\n",
       "0     4  The Rock is destined to be the 21st Century 's...\n",
       "1     5  The gorgeously elaborate continuation of `` Th...\n",
       "2     4  Singer/composer Bryan Adams contributes a slew...\n",
       "3     3  You 'd think by now America would have had eno...\n",
       "4     4               Yet the act is still charming here ."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the first 5 observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data - have 8544 training observations\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into the data\n",
    "# What is the distribution of the data like? Particularly, by truth\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Label')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['truth'].value_counts(sort=False).plot(kind='barh', color = \"orange\")\n",
    "ax.set_xlabel('Number of Samples in training Set')\n",
    "ax.set_ylabel('Label')\n",
    "# Most ratings are a 4 and 2, weakly negative/positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that stores the string length of each text sample\n",
    "# Sort the DataFrame rows in ascending order of their text lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['text'].str.len()  # Store string length of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>3</td>\n",
       "      <td>Go .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8484</th>\n",
       "      <td>3</td>\n",
       "      <td>Eh .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>4</td>\n",
       "      <td>Wow .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>2</td>\n",
       "      <td>No. .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>3</td>\n",
       "      <td>A. . .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4</td>\n",
       "      <td>Cool .</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>3</td>\n",
       "      <td>Bang !</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>4</td>\n",
       "      <td>Zoom !</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>2</td>\n",
       "      <td>Weird .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>3</td>\n",
       "      <td>C'mon !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8304</th>\n",
       "      <td>3</td>\n",
       "      <td>Please .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>3</td>\n",
       "      <td>Renner ?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>2</td>\n",
       "      <td>A mess .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>5</td>\n",
       "      <td>See it .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>3</td>\n",
       "      <td>ending .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>3</td>\n",
       "      <td>Barely .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>3</td>\n",
       "      <td>TouchÈ !</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>5</td>\n",
       "      <td>See it .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>1</td>\n",
       "      <td>Crummy .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>3</td>\n",
       "      <td>Spy-vs .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>3</td>\n",
       "      <td>Almost .</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>2</td>\n",
       "      <td>Too bad .</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>5</td>\n",
       "      <td>Amazing !</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     truth       text  len\n",
       "593      3       Go .    4\n",
       "8484     3       Eh .    4\n",
       "4198     4      Wow .    5\n",
       "5286     4      Yes .    5\n",
       "5288     2      No. .    5\n",
       "1270     2      Why ?    5\n",
       "2038     3     A. . .    6\n",
       "335      4     Cool .    6\n",
       "7669     3     Bang !    6\n",
       "7670     4     Zoom !    6\n",
       "8388     2    Weird .    7\n",
       "2083     3    C'mon !    7\n",
       "8304     3   Please .    8\n",
       "2185     3   Renner ?    8\n",
       "5655     2   A mess .    8\n",
       "2382     5   See it .    8\n",
       "5418     3   ending .    8\n",
       "8536     3   Barely .    8\n",
       "8353     3   TouchÈ !    8\n",
       "8359     5   See it .    8\n",
       "8521     1   Crummy .    8\n",
       "7997     3   Spy-vs .    8\n",
       "4130     3   Almost .    8\n",
       "5748     2  Too bad .    9\n",
       "776      5  Amazing !    9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['len'], ascending=True)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea here is that observations that have limited context and only a few characters in length can mess up the prediction \n",
    "capability of the model. For instance, the word \"cool\" is all by itself, yet the model is giving this one word sentence\n",
    "a really high truth rating of 4 (weakly positive). But, we all know cool is more of an understanding, \n",
    "not a strength of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning and Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Base class is defined in Python that contains the commonly used methods: one for reading in the SST-5 data into a Pandas DataFrame (read_data), and another to calculate the model’s classification accuracy and F1-score (accuracy).\n",
    "- Each individual classifier added to the framework must inherit the Base class defined above.\n",
    "- a score method and a predict method are included with each new sentiment classifier, as shown below.\n",
    "- The score method outputs a unique sentiment class for a text sample\n",
    "- The predict method applies the score method to every sample in the test dataset to output a new column, 'pred' in the test DataFrame.\n",
    "- Compute the model's accuracy and F1 Scores by using the accuracy method based in Base class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Scoring\n",
    "- Sentiment Scoring\n",
    "- Need to convert our values to type discrete\n",
    "- The continous \"compound\" polarity score (float) is converted to a discrete value using binning through pd.cut function\n",
    "- Returns 1 of 5 classes for each test sample, stored a a new column in the resulting dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all of the classes for the files, accuracy, score, and machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    \"\"\"Base class that houses common utilities for reading in test data\n",
    "    and calculating model accuracy and F1 scores.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def read_data(self, fname: str, lower_case: bool=False,\n",
    "                  colnames=['truth', 'text']) -> pd.DataFrame:\n",
    "        \"Read in test data into a Pandas DataFrame\"\n",
    "        df = pd.read_csv(fname, sep=',', header=None, names=colnames)\n",
    "        df['truth'] = df['truth'].str.replace('__label__', '')\n",
    "        # Categorical data type for truth labels\n",
    "        df['truth'] = df['truth'].astype(int).astype('category')\n",
    "        # Optional lowercase for test data (if model was trained on lowercased text)\n",
    "        if lower_case:\n",
    "            df['text'] = df['text'].str.lower()\n",
    "        return df\n",
    "\n",
    "    def accuracy(self, df: pd.DataFrame) -> None:\n",
    "        \"Prediction accuracy (percentage) and F1 score\"\n",
    "        acc = accuracy_score(df['truth'], df['pred'])*100\n",
    "        f1 = f1_score(df['truth'], df['pred'], average='macro')\n",
    "        print(\"Accuracy: {}\\nMacro F1-score: {}\".format(acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleSentiment(Base):\n",
    "    \"\"\"Predict sentiment scores using using X classifier\"\"\"\n",
    "    def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()   # Inherit methods from Base class\n",
    "\n",
    "    def score(self, text: str) -> int:\n",
    "        \"\"\"Return a sentiment score on sample text, an integer in the range [1, 2, 3, 4, 5]\"\"\"\n",
    "        # Apply some sentiment scoring technique here\n",
    "        \n",
    "    def predict(self, train_file: None, test_file: str, lower_case: bool) -> pd.DataFrame:\n",
    "        \"\"\"Return a Pandas DataFrame that applies the sentiment scoring method on each\n",
    "           row of the test set\n",
    "        \"\"\"\n",
    "        df = self.read_data(test_file, lower_case)\n",
    "        df['pred'] = df['text'].apply(self.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaderSentiment(Base):\n",
    "    \"\"\"Predict fine-grained sentiment classes using Vader.\"\"\"\n",
    "    def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        self.vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def score(self, text: str) -> float:\n",
    "        return self.vader.polarity_scores(text)['compound']\n",
    "\n",
    "    def predict(self, train_file: None, test_file: str, lower_case: bool) -> pd.DataFrame:\n",
    "        \"Return DataFrame with a new column of predicted labels\"\n",
    "        df = self.read_data(test_file, lower_case)\n",
    "        df['score'] = df['text'].apply(self.score)\n",
    "        # Convert float score to category based on binning\n",
    "        df['pred'] = pd.cut(df['score'], bins=5, labels=[1, 2, 3, 4, 5])\n",
    "        df = df.drop('score', axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionSentiment(Base):\n",
    "    \"\"\"Predict fine-grained sentiment scores using a sklearn Logistic Regression pipeline.\"\"\"\n",
    "    def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        self.pipeline = Pipeline(\n",
    "            [\n",
    "                ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver='liblinear', multi_class='auto')),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def predict(self, train_file: str, test_file: str, lower_case: bool=False) -> pd.DataFrame:\n",
    "        \"Train model using sklearn pipeline\"\n",
    "        train_df = self.read_data(train_file, lower_case)\n",
    "        learner = self.pipeline.fit(train_df['text'], train_df['truth'])\n",
    "        # Predict class labels using the learner and output DataFrame\n",
    "        test_df = self.read_data(test_file, lower_case)\n",
    "        test_df['pred'] = learner.predict(test_df['text'])\n",
    "        return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMSentiment(Base):\n",
    "    \"\"\"Predict fine-grained sentiment scores using a sklearn \n",
    "    linear Support Vector Machine (SVM) pipeline.\"\"\"\n",
    "    def __init__(self, model_file: str=None) -> None:\n",
    "        super().__init__()\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        self.pipeline = Pipeline(\n",
    "            [\n",
    "                ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(\n",
    "                    loss='hinge',\n",
    "                    penalty='l2',\n",
    "                    alpha=1e-3,\n",
    "                    random_state=42,\n",
    "                    max_iter=100,\n",
    "                    learning_rate='optimal',\n",
    "                    tol=None,\n",
    "                )),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def predict(self, train_file: str, test_file: str, lower_case: bool=False) -> pd.DataFrame:\n",
    "        \"Train model using sklearn pipeline\"\n",
    "        train_df = self.read_data(train_file, lower_case)\n",
    "        learner = self.pipeline.fit(train_df['text'], train_df['truth'])\n",
    "        # Predict class labels using the learner and output DataFrame\n",
    "        test_df = self.read_data(test_file, lower_case)\n",
    "        test_df['pred'] = learner.predict(test_df['text'])\n",
    "        return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth    category\n",
      "text       object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  truth                                               text\n",
       "0     3                     Effective but too-tepid biopic\n",
       "1     4  If you sometimes like to go to the movies to h...\n",
       "2     5  Emerges as something rare , an issue movie tha...\n",
       "3     3  The film provides some great insight into the ...\n",
       "4     5  Offers that rare combination of entertainment ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read test data and split the columns by a comma and create two new headings\n",
    "df = pd.read_csv(\"sst_test.csv\", sep=',', header=None, names=['truth', 'text'])\n",
    "df['truth'] = df['truth'].str.replace('__label__', '')\n",
    "df['truth'] = df['truth'].astype(int).astype('category')\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "def score_vader(sentence, vader):\n",
    "    return vader.polarity_scores(sentence)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "      <th>vader_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  truth                                               text vader_pred\n",
       "0     3                     Effective but too-tepid biopic          4\n",
       "1     4  If you sometimes like to go to the movies to h...          5\n",
       "2     5  Emerges as something rare , an issue movie tha...          5\n",
       "3     3  The film provides some great insight into the ...          5\n",
       "4     5  Offers that rare combination of entertainment ...          4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Vader sentiment score\n",
    "df['vader_score'] = df['text'].apply(lambda x: score_vader(x, vader))\n",
    "# Convert float score to category based on binning\n",
    "df['vader_pred'] = pd.cut(df['vader_score'], bins=5, labels=[1, 2, 3, 4, 5])\n",
    "df = df.drop('vader_score', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(df, pred_column):\n",
    "    \"Print f1 score and accuracy after making predictions\"\n",
    "    f1_macro = f1_score(df['truth'], df[pred_column], average='macro')\n",
    "    acc = accuracy_score(df['truth'], df[pred_column])*100\n",
    "    return f1_macro, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1-score: 0.31297326018199634\n",
      "Accuracy: 31.538461538461537\n"
     ]
    }
   ],
   "source": [
    "# Get model accuracy and f1 score\n",
    "acc = print_accuracy(df, 'vader_pred')\n",
    "print(\"Macro F1-score: {}\\nAccuracy: {}\".format(acc[0], acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Object Oriented Programming - Machine Learning Vader Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses a sentiment lexicon that contains intensity measures for each word based on human-annotated labels\n",
    "- Designed with a focus on social media texts\n",
    "- This means that it puts a lot of emphasis on rules that capture the essence of text typically seen on social media\n",
    "- for example, short sentences with emojis, repetitive vocabulary and copious use of punctuation\n",
    "- VADER breaks down sentiment intensity scores into a positive, negative and neutral component, which are then normalized and squashed to be within the range [-1, 1] as a “compound” score\n",
    "- As we add more exclamation marks, capitalization and emojis/emoticons, the intensity gets more and more extreme (towards +/- 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "testA = Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = testA.read_data(\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Vader Sentiment\n",
    "c = VaderSentiment(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a prediction score for Vader Sentiment from our test set now\n",
    "e = c.predict(\"sst_train\",\"sst_test.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>4</td>\n",
       "      <td>an imaginative comedy/thriller .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>5</td>\n",
       "      <td>( a ) rare , beautiful film .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>5</td>\n",
       "      <td>( an ) hilarious romantic comedy .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>4</td>\n",
       "      <td>never ( sinks ) into exploitation .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>1</td>\n",
       "      <td>( u ) nrelentingly stupid .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     truth                                               text pred\n",
       "0        3                     effective but too-tepid biopic    4\n",
       "1        4  if you sometimes like to go to the movies to h...    5\n",
       "2        5  emerges as something rare , an issue movie tha...    5\n",
       "3        3  the film provides some great insight into the ...    5\n",
       "4        5  offers that rare combination of entertainment ...    4\n",
       "...    ...                                                ...  ...\n",
       "2205     4                   an imaginative comedy/thriller .    3\n",
       "2206     5                      ( a ) rare , beautiful film .    5\n",
       "2207     5                 ( an ) hilarious romantic comedy .    5\n",
       "2208     4                never ( sinks ) into exploitation .    3\n",
       "2209     1                        ( u ) nrelentingly stupid .    2\n",
       "\n",
       "[2210 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.538461538461537\n",
      "Macro F1-score: 0.3132222711234521\n"
     ]
    }
   ],
   "source": [
    "f = testA.accuracy(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the model to predict on other text \n",
    "# Based on text\n",
    "# Import text from Rotten Tomatoes\n",
    "d = c.score(\"This is horrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5423"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The score of the text\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Object Oriented Programming - Machine Learning Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The input features and their weights are fed into an activation function (a sigmoid for binary classification, or a softmax for multi-class). The output of the classifier is just the index of the sigmoid/softmax vector with the highest value as the class label.\n",
    "- Use scikit-learn’s CountVectorizer to transform the text into features\n",
    "- This converts the entire corpus (i.e. all sentences) of our training data into a matrix of token counts.\n",
    "- The count matrix is converted to a TF-IDF (Term-frequency Inverse document frequency) representation.\n",
    "- Once we obtain the TF-IDF representation of the training corpus, the classifier is trained by fitting it to the existing features.\n",
    "- A “newton-cg” solver is used for optimizing the loss in the logistic regression and L2 regularization is used by default.\n",
    "- A sentiment label is returned for each test sample (using scikit-learn’s learner.predict method) as the index of the maximum class probability in the softmax output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "testB = Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = testB.read_data(\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Vader Sentiment\n",
    "m = LogisticRegressionSentiment(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a prediction score for Logistic Regression from our test set now\n",
    "n = m.predict(\"sst_train.csv\",\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>4</td>\n",
       "      <td>An imaginative comedy/thriller .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>5</td>\n",
       "      <td>( A ) rare , beautiful film .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>5</td>\n",
       "      <td>( An ) hilarious romantic comedy .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>4</td>\n",
       "      <td>Never ( sinks ) into exploitation .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>1</td>\n",
       "      <td>( U ) nrelentingly stupid .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     truth                                               text  pred\n",
       "0        3                     Effective but too-tepid biopic     2\n",
       "1        4  If you sometimes like to go to the movies to h...     4\n",
       "2        5  Emerges as something rare , an issue movie tha...     5\n",
       "3        3  The film provides some great insight into the ...     4\n",
       "4        5  Offers that rare combination of entertainment ...     5\n",
       "...    ...                                                ...   ...\n",
       "2205     4                   An imaginative comedy/thriller .     4\n",
       "2206     5                      ( A ) rare , beautiful film .     5\n",
       "2207     5                 ( An ) hilarious romantic comedy .     5\n",
       "2208     4                Never ( sinks ) into exploitation .     2\n",
       "2209     1                        ( U ) nrelentingly stupid .     1\n",
       "\n",
       "[2210 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.18099547511312\n",
      "Macro F1-score: 0.3295860165192341\n"
     ]
    }
   ],
   "source": [
    "o = testB.accuracy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Object Oriented Programming - Machine Learning Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use of “kernel functions”, i.e. functions that transform a complex, nonlinear decision space to one that has higher dimensionality, so that an appropriate hyperplane separating the data points can be found. \n",
    "- The SVM classifier looks to maximize the distance of each data point from this hyperplane using “support vectors” that characterize each distance as a vector.\n",
    "- A key feature of SVMs is the fact that it uses a hinge loss rather than a logistic loss. This makes it more robust to outliers in the data, since the hinge loss does not diverge as quickly as a logistic loss.\n",
    "- Obtain the TF-IDF representation of the training corpus\n",
    "- Train the SVM model by fitting it to the training data features\n",
    "- A hinge loss function with a stochastic gradient descent (SGD) optimizer is used, and L2 regularization is applied during training. \n",
    "- The sentiment label is returned (using scikit-learn’s learner.predict method) as the index of the maximum class probability in the softmax output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "testC = Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = testC.read_data(\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Logistic Regression Class\n",
    "q = LogisticRegressionSentiment(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a prediction score for Logistic Regression from our test set now\n",
    "v = q.predict(\"sst_train.csv\",\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The film provides some great insight into the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Offers that rare combination of entertainment ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>4</td>\n",
       "      <td>An imaginative comedy/thriller .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>5</td>\n",
       "      <td>( A ) rare , beautiful film .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>5</td>\n",
       "      <td>( An ) hilarious romantic comedy .</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>4</td>\n",
       "      <td>Never ( sinks ) into exploitation .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>1</td>\n",
       "      <td>( U ) nrelentingly stupid .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     truth                                               text  pred\n",
       "0        3                     Effective but too-tepid biopic     2\n",
       "1        4  If you sometimes like to go to the movies to h...     4\n",
       "2        5  Emerges as something rare , an issue movie tha...     5\n",
       "3        3  The film provides some great insight into the ...     4\n",
       "4        5  Offers that rare combination of entertainment ...     5\n",
       "...    ...                                                ...   ...\n",
       "2205     4                   An imaginative comedy/thriller .     4\n",
       "2206     5                      ( A ) rare , beautiful film .     5\n",
       "2207     5                 ( An ) hilarious romantic comedy .     5\n",
       "2208     4                Never ( sinks ) into exploitation .     2\n",
       "2209     1                        ( U ) nrelentingly stupid .     1\n",
       "\n",
       "[2210 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.18099547511312\n",
      "Macro F1-score: 0.3295860165192341\n"
     ]
    }
   ],
   "source": [
    "w = testC.accuracy(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured Data: Pulling data from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the appropriate libraries\n",
    "import requests # pip install requests\n",
    "from bs4 import BeautifulSoup #pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review = soup.findAll('div', {'class' :'text show-more__control'})\n",
    "    review4 = review[4]\n",
    "    return(review4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_as_text = review.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have never seen such an amazing film since I saw The Shawshank Redemption. Shawshank encompasses friendships, hardships, hopes, and dreams.  And what is so great about the movie is that it moves you, it gives you hope.  Even though the circumstances between the characters and the viewers are quite different, you don't feel that far removed from what the characters are going through.It is a simple film, yet it has an everlasting message.  Frank Darabont didn't need to put any kind of outlandish special effects to get us to love this film, the narration and the acting does that for him.  Why this movie didn't win all seven Oscars is beyond me, but don't let that sway you to not see this film, let its ranking on the IMDb's top 250 list sway you, let your friends recommendation about the movie sway you.Set aside a little over two hours tonight and rent this movie.  You will finally understand what everyone is talking about and you will understand why this is my all time favorite movie.\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_as_text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing text via Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment score of this texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "testA = Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = testA.read_data(\"sst_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Vader Sentiment\n",
    "c = VaderSentiment(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a prediction score for Vader Sentiment from our test set now\n",
    "e = c.predict(\"sst_train\",\"sst_test.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a score for the text pulled from IMDB\n",
    "d = c.score(review_as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Score\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Review and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a recap the text we pulled in from IMDB:\n",
    "    - \"I have never seen such an amazing film since I saw The Shawshank Redemption. Shawshank encompasses friendships, hardships, hopes, and dreams.  And what is so great about the movie is that it moves you, it gives you hope.  Even though the circumstances between the characters and the viewers are quite different, you don't feel that far removed from what the characters are going through.It is a simple film, yet it has an everlasting message.  Frank Darabont didn't need to put any kind of outlandish special effects to get us to love this film, the narration and the acting does that for him.  Why this movie didn't win all seven Oscars is beyond me, but don't let that sway you to not see this film, let its ranking on the IMDb's top 250 list sway you, let your friends recommendation about the movie sway you.Set aside a little over two hours tonight and rent this movie.  You will finally understand what everyone is talking about and you will understand why this is my all time favorite movie.\"\n",
    "    - Confident that from a non machine learning approach - this is a very positive review\n",
    "- The Vadar sentiment score ranges from [-1, 1] with 1 being very positive. \n",
    "- The score, as witnessed above, is .9682. This machine learning model also predicts this review to be extremely positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
